{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detection of Hydrogen Pressure Multivariate Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, make_scorer\n",
    "import numpy as np\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.ensemble import IsolationForest, RandomForestClassifier\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import pygad\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.legend_handler import HandlerPathCollection\n",
    "from tsfresh import extract_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "from tsfresh import select_features\n",
    "import plotly.graph_objects as go\n",
    "import warnings\n",
    "from itertools import cycle\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Description "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_normale = pd.read_csv(\"raw_normal_dataset_def.csv\")\n",
    "\n",
    "print(\"Dataset Normale:\")\n",
    "print(\"\\nDescription dataset:\")\n",
    "dataset_normale.Time = pd.to_datetime(dataset_normale.Time, infer_datetime_format=True, unit='s')\n",
    "dataset_normale['Time'] = dataset_normale['Time'].apply(lambda x: x.replace(year=2024,month=5, day=15))\n",
    "display(dataset_normale)\n",
    "print(dataset_normale.info())\n",
    "print(dataset_normale.iloc[:, 1:7].shape)\n",
    "print(dataset_normale.iloc[:, 1:7].describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_anomalo_1 = pd.read_csv(\"raw_anomaly1_dataset_def.csv\")\n",
    "print(\"Dataset Anomalia 1:\")\n",
    "print(\"\\nDescription dataset:\")\n",
    "dataset_anomalo_1.Time = pd.to_datetime(dataset_anomalo_1.Time, infer_datetime_format=True, unit='s')\n",
    "dataset_anomalo_1['Time'] = dataset_anomalo_1['Time'].apply(lambda x: x.replace(year=2024,month=5, day=15))\n",
    "display(dataset_anomalo_1)\n",
    "print(dataset_anomalo_1.info())\n",
    "print(dataset_anomalo_1.iloc[:, 1:7].shape)\n",
    "print(dataset_anomalo_1.iloc[:, 1:7].describe())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_anomalo_2 = pd.read_csv(\"raw_anomaly2_dataset_def.csv\")\n",
    "print(\"Dataset Anomalia 2:\")\n",
    "print(\"\\nDescription dataset:\")\n",
    "dataset_anomalo_2.Time = pd.to_datetime(dataset_anomalo_2.Time, infer_datetime_format=True, unit='s')\n",
    "dataset_anomalo_2['Time'] = dataset_anomalo_2['Time'].apply(lambda x: x.replace(year=2024,month=5, day=15))\n",
    "display(dataset_anomalo_2)\n",
    "print(dataset_anomalo_2.info())\n",
    "print(dataset_anomalo_2.iloc[:, 1:7].shape)\n",
    "print(dataset_anomalo_2.iloc[:, 1:7].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_anomalo_3 = pd.read_csv(\"raw_anomaly3_dataset_def.csv\")\n",
    "print(\"Dataset Anomalia 3:\")\n",
    "print(\"\\nDescription dataset:\")\n",
    "dataset_anomalo_3.Time = pd.to_datetime(dataset_anomalo_3.Time, infer_datetime_format=True, unit='s')\n",
    "dataset_anomalo_3['Time'] = dataset_anomalo_3['Time'].apply(lambda x: x.replace(year=2024,month=5, day=15))\n",
    "display(dataset_anomalo_3)\n",
    "print(dataset_anomalo_3.info())\n",
    "print(dataset_anomalo_3.iloc[:, 1:7].shape)\n",
    "print(dataset_anomalo_3.iloc[:, 1:7].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Multivariate Time Series Raw Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "layout = dict(xaxis=dict(title='Time'), yaxis=dict(title='Pressure'))\n",
    "\n",
    "fig = go.Figure(layout=layout)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=dataset_normale.Time, y=dataset_normale.PS_1, \n",
    "                         mode='markers',\n",
    "                         marker=dict(color='red')))\n",
    "fig.add_trace(go.Scatter(x=dataset_normale.Time, y=dataset_normale.PS_2, \n",
    "                         mode='markers',\n",
    "                         marker=dict(color='blue')))\n",
    "fig.add_trace(go.Scatter(x=dataset_normale.Time, y=dataset_normale.PS_3, \n",
    "                         mode='markers',\n",
    "                         marker=dict(color='green')))\n",
    "fig.add_trace(go.Scatter(x=dataset_normale.Time, y=dataset_normale.PS_4, \n",
    "                         mode='markers',\n",
    "                         marker=dict(color='yellow')))\n",
    "fig.add_trace(go.Scatter(x=dataset_normale.Time, y=dataset_normale.PS_5, \n",
    "                         mode='markers',\n",
    "                         marker=dict(color='orange')))\n",
    "\n",
    "names = cycle(['PS_1', 'PS_2','PS_3','PS_4','PS_5'])\n",
    "fig.for_each_trace(lambda t:  t.update(name = next(names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = dict(xaxis=dict(title='Time'), yaxis=dict(title='Pressure'))\n",
    "\n",
    "fig = go.Figure(layout=layout)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=dataset_anomalo_1.Time, y=dataset_anomalo_1.PS_1, \n",
    "                         mode='markers',\n",
    "                         marker=dict(color='red')))\n",
    "fig.add_trace(go.Scatter(x=dataset_anomalo_1.Time, y=dataset_anomalo_1.PS_2, \n",
    "                         mode='markers',\n",
    "                         marker=dict(color='blue')))\n",
    "fig.add_trace(go.Scatter(x=dataset_anomalo_1.Time, y=dataset_anomalo_1.PS_3, \n",
    "                         mode='markers',\n",
    "                         marker=dict(color='green')))\n",
    "fig.add_trace(go.Scatter(x=dataset_anomalo_1.Time, y=dataset_anomalo_1.PS_4, \n",
    "                         mode='markers',\n",
    "                         marker=dict(color='yellow')))\n",
    "fig.add_trace(go.Scatter(x=dataset_anomalo_1.Time, y=dataset_anomalo_1.PS_5, \n",
    "                         mode='markers',\n",
    "                         marker=dict(color='orange')))\n",
    "\n",
    "names = cycle(['PS_1', 'PS_2','PS_3','PS_4','PS_5'])\n",
    "fig.for_each_trace(lambda t:  t.update(name = next(names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = dict(xaxis=dict(title='Time'), yaxis=dict(title='Pressure'))\n",
    "\n",
    "fig = go.Figure(layout=layout)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=dataset_anomalo_2.Time, y=dataset_anomalo_2.PS_1, \n",
    "                         mode='markers',\n",
    "                         marker=dict(color='red')))\n",
    "fig.add_trace(go.Scatter(x=dataset_anomalo_2.Time, y=dataset_anomalo_2.PS_2, \n",
    "                         mode='markers',\n",
    "                         marker=dict(color='blue')))\n",
    "fig.add_trace(go.Scatter(x=dataset_anomalo_2.Time, y=dataset_anomalo_2.PS_3, \n",
    "                         mode='markers',\n",
    "                         marker=dict(color='green')))\n",
    "fig.add_trace(go.Scatter(x=dataset_anomalo_2.Time, y=dataset_anomalo_2.PS_4, \n",
    "                         mode='markers',\n",
    "                         marker=dict(color='yellow')))\n",
    "fig.add_trace(go.Scatter(x=dataset_anomalo_2.Time, y=dataset_anomalo_2.PS_5, \n",
    "                         mode='markers',\n",
    "                         marker=dict(color='orange')))\n",
    "\n",
    "names = cycle(['PS_1', 'PS_2','PS_3','PS_4','PS_5'])\n",
    "fig.for_each_trace(lambda t:  t.update(name = next(names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = dict(xaxis=dict(title='Time'), yaxis=dict(title='Pressure'))\n",
    "\n",
    "fig = go.Figure(layout=layout)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=dataset_anomalo_3.Time, y=dataset_anomalo_3.PS_1, \n",
    "                         mode='markers',\n",
    "                         marker=dict(color='red')))\n",
    "fig.add_trace(go.Scatter(x=dataset_anomalo_3.Time, y=dataset_anomalo_3.PS_2, \n",
    "                         mode='markers',\n",
    "                         marker=dict(color='blue')))\n",
    "fig.add_trace(go.Scatter(x=dataset_anomalo_3.Time, y=dataset_anomalo_3.PS_3, \n",
    "                         mode='markers',\n",
    "                         marker=dict(color='green')))\n",
    "fig.add_trace(go.Scatter(x=dataset_anomalo_3.Time, y=dataset_anomalo_3.PS_4, \n",
    "                         mode='markers',\n",
    "                         marker=dict(color='yellow')))\n",
    "fig.add_trace(go.Scatter(x=dataset_anomalo_3.Time, y=dataset_anomalo_3.PS_5, \n",
    "                         mode='markers',\n",
    "                         marker=dict(color='orange')))\n",
    "\n",
    "names = cycle(['PS_1', 'PS_2','PS_3','PS_4','PS_5'])\n",
    "fig.for_each_trace(lambda t:  t.update(name = next(names)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_normale.reset_index(inplace=True)\n",
    "dataset_normale.rename(columns={'index': 'ID'}, inplace=True)\n",
    "dataset_anomalo_1.reset_index(inplace=True)\n",
    "dataset_anomalo_1.rename(columns={'index': 'ID'}, inplace=True)\n",
    "dataset_anomalo_2.reset_index(inplace=True)\n",
    "dataset_anomalo_2.rename(columns={'index': 'ID'}, inplace=True)\n",
    "dataset_anomalo_3.reset_index(inplace=True)\n",
    "dataset_anomalo_3.rename(columns={'index': 'ID'}, inplace=True)\n",
    "\n",
    "y_tot = pd.concat([dataset_normale['Y'], dataset_anomalo_1['Y'],  dataset_anomalo_2['Y'],  dataset_anomalo_3['Y']], ignore_index=True)\n",
    "extracted_features_norm = extract_features(dataset_normale.drop(columns='Y'), column_id=\"ID\", column_sort=\"Time\")\n",
    "\n",
    "extracted_features_anom_1 = extract_features(dataset_anomalo_1.drop(columns='Y'), column_id=\"ID\", column_sort=\"Time\")\n",
    "\n",
    "extracted_features_anom_2 = extract_features(dataset_anomalo_2.drop(columns='Y'), column_id=\"ID\", column_sort=\"Time\")\n",
    "\n",
    "extracted_features_anom_3 = extract_features(dataset_anomalo_3.drop(columns='Y'), column_id=\"ID\", column_sort=\"Time\")\n",
    "\n",
    "impute(extracted_features_norm)\n",
    "impute(extracted_features_anom_1)\n",
    "impute(extracted_features_anom_2)\n",
    "impute(extracted_features_anom_3)\n",
    "\n",
    "extracted_features_total = pd.concat([extracted_features_norm,  extracted_features_anom_1, extracted_features_anom_2,  extracted_features_anom_3], ignore_index=True)\n",
    "display(extracted_features_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_filtered = select_features(extracted_features_total, y_tot)\n",
    "display(features_filtered)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Dataset : Train, Validation and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features_filtered.values  \n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_scaled, y_tot, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detection Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Class SVM:  Hyperparameter Optimization with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneclass_svm = OneClassSVM()\n",
    " \n",
    "param_grid = {\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'nu': np.linspace(0.01, 1, 5),\n",
    "    'gamma': np.linspace(0.01, 1, 5)\n",
    "}\n",
    " \n",
    "f1_scorer = make_scorer(f1_score, average='binary')\n",
    "grid_search = GridSearchCV(estimator=oneclass_svm, param_grid=param_grid, scoring=f1_scorer, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    " \n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation F1 score: \", grid_search.best_score_)\n",
    " \n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_val = best_model.predict(X_val)\n",
    "accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "f1_score_val = f1_score(y_val, y_pred_val, pos_label=1)\n",
    "confusion_matrix_val = confusion_matrix(y_val, y_pred_val, labels=[1,-1])\n",
    "print('accuracy_val: ',accuracy_val)\n",
    "print('f1_score_val: ',f1_score_val)\n",
    " \n",
    " \n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_matrix_val, annot=True, cmap='Blues', fmt='g', xticklabels=[1, -1], yticklabels=[1, -1])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix Validation Set')\n",
    "plt.show()\n",
    " \n",
    " \n",
    "y_pred_test = best_model.predict(X_test)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "f1_score_test = f1_score(y_test, y_pred_test, pos_label=1)\n",
    "confusion_matrix_test = confusion_matrix(y_test, y_pred_test, labels=[1,-1])\n",
    "print('accuracy_test: ',accuracy_test)\n",
    "print('f1_score_test: ',f1_score_test)\n",
    " \n",
    " \n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_matrix_test, annot=True, cmap='Blues', fmt='g', xticklabels=[1, -1], yticklabels=[1, -1])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix Test Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Isolation Forest:  Hyperparameter Optimization with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_forest = IsolationForest()\n",
    " \n",
    "param_grid = {\n",
    "    'n_estimators': list(range(1,5)),\n",
    "    'contamination': np.linspace(0.1, 0.5, 5) ,\n",
    "    'max_features': np.linspace(0.1, 1.0, 5),\n",
    "    'bootstrap': True,\n",
    "    'random_state': 42\n",
    "}\n",
    " \n",
    " \n",
    "f1_scorer = make_scorer(f1_score, average='binary')\n",
    "grid_search = GridSearchCV(estimator=iso_forest, param_grid=param_grid, scoring=f1_scorer, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    " \n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation F1 score: \", grid_search.best_score_)\n",
    " \n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_val = best_model.predict(X_val)\n",
    "accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "f1_score_val = f1_score(y_val, y_pred_val, pos_label=1)\n",
    "confusion_matrix_val = confusion_matrix(y_val, y_pred_val, labels=[1,-1])\n",
    "print('accuracy_val: ',accuracy_val)\n",
    "print('f1_score_val: ',f1_score_val)\n",
    " \n",
    " \n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_matrix_val, annot=True, cmap='Blues', fmt='g', xticklabels=[1, -1], yticklabels=[1, -1])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix Validation Set')\n",
    "plt.show()\n",
    " \n",
    " \n",
    "y_pred_test = best_model.predict(X_test)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "f1_score_test = f1_score(y_test, y_pred_test, pos_label=1)\n",
    "confusion_matrix_test = confusion_matrix(y_test, y_pred_test, labels=[1,-1])\n",
    "print('accuracy_test: ',accuracy_test)\n",
    "print('f1_score_test: ',f1_score_test)\n",
    " \n",
    " \n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_matrix_test, annot=True, cmap='Blues', fmt='g', xticklabels=[1, -1], yticklabels=[1, -1])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix Test Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest:  Hyperparameter Optimization with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forest = RandomForestClassifier()\n",
    " \n",
    "param_grid = {\n",
    "    'n_estimators': list(range(1,5)),\n",
    "    'max_depth': list(range(1,10)),\n",
    "    'random_state': 42,\n",
    "    'max_samples':  np.linspace(0.1, 0.5, 5),\n",
    "    'bootstrap': True\n",
    "}\n",
    " \n",
    "f1_scorer = make_scorer(f1_score, average='binary')\n",
    "grid_search = GridSearchCV(estimator=rand_forest, param_grid=param_grid, scoring=f1_scorer, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    " \n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation F1 score: \", grid_search.best_score_)\n",
    " \n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_val = best_model.predict(X_val)\n",
    "accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "f1_score_val = f1_score(y_val, y_pred_val, pos_label=1)\n",
    "confusion_matrix_val = confusion_matrix(y_val, y_pred_val, labels=[1,-1])\n",
    "print('accuracy_val: ',accuracy_val)\n",
    "print('f1_score_val: ',f1_score_val)\n",
    " \n",
    " \n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_matrix_val, annot=True, cmap='Blues', fmt='g', xticklabels=[1, -1], yticklabels=[1, -1])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix Validation Set')\n",
    "plt.show()\n",
    " \n",
    " \n",
    "y_pred_test = best_model.predict(X_test)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "f1_score_test = f1_score(y_test, y_pred_test, pos_label=1)\n",
    "confusion_matrix_test = confusion_matrix(y_test, y_pred_test, labels=[1,-1])\n",
    "print('accuracy_test: ',accuracy_test)\n",
    "print('f1_score_test: ',f1_score_test)\n",
    " \n",
    " \n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_matrix_test, annot=True, cmap='Blues', fmt='g', xticklabels=[1, -1], yticklabels=[1, -1])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix Test Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Outlier Factor:  Hyperparameter Optimization with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_outl = LocalOutlierFactor()\n",
    " \n",
    "param_grid = {\n",
    "    'algorithm': ['ball_tree', 'kd_tree'],\n",
    "    'n_neighbors': list(range(10,15)),\n",
    "    'leaf_size' : list(range(30,35)),\n",
    "    'contamination': np.linspace(0.1, 0.5, 5), \n",
    "    'novelty': True\n",
    "}\n",
    " \n",
    "f1_scorer = make_scorer(f1_score, average='binary')\n",
    "grid_search = GridSearchCV(estimator=loc_outl, param_grid=param_grid, scoring=f1_scorer, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    " \n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation F1 score: \", grid_search.best_score_)\n",
    " \n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_val = best_model.predict(X_val)\n",
    "accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "f1_score_val = f1_score(y_val, y_pred_val, pos_label=1)\n",
    "confusion_matrix_val = confusion_matrix(y_val, y_pred_val, labels=[1,-1])\n",
    "print('accuracy_val: ',accuracy_val)\n",
    "print('f1_score_val: ',f1_score_val)\n",
    " \n",
    " \n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_matrix_val, annot=True, cmap='Blues', fmt='g', xticklabels=[1, -1], yticklabels=[1, -1])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix Validation Set')\n",
    "plt.show()\n",
    " \n",
    " \n",
    "y_pred_test = best_model.predict(X_test)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "f1_score_test = f1_score(y_test, y_pred_test, pos_label=1)\n",
    "confusion_matrix_test = confusion_matrix(y_test, y_pred_test, labels=[1,-1])\n",
    "print('accuracy_test: ',accuracy_test)\n",
    "print('f1_score_test: ',f1_score_test)\n",
    " \n",
    " \n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_matrix_test, annot=True, cmap='Blues', fmt='g', xticklabels=[1, -1], yticklabels=[1, -1])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix Test Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scores = loc_outl.negative_outlier_factor_\n",
    " \n",
    " \n",
    "y_pred_val = loc_outl.predict(X_val)\n",
    "n_errors = (y_pred_val != y_val).sum()\n",
    " \n",
    " \n",
    "def update_legend_marker_size(handle, orig):\n",
    "    \"Personalizza la dimensione del marcatore della legenda\"\n",
    "    handle.update_from(orig)\n",
    "    handle.set_sizes([20])\n",
    " \n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], color=\"k\", s=3.0, label=\"Data points\")\n",
    "radius = (X_scores.max() - X_scores) / (X_scores.max() - X_scores.min())\n",
    "scatter = plt.scatter(\n",
    "    X_train[:, 0],\n",
    "    X_train[:, 1],\n",
    "    s=1000 * radius,\n",
    "    edgecolors=\"r\",\n",
    "    facecolors=\"none\",\n",
    "    label=\"Outlier scores\",\n",
    ")\n",
    "plt.axis(\"tight\")\n",
    "plt.xlim((-5, 5))\n",
    "plt.ylim((-5, 5))\n",
    "plt.xlabel(\"prediction errors: %d\" % (n_errors))\n",
    "plt.legend(\n",
    "    handler_map={scatter: HandlerPathCollection(update_func=update_legend_marker_size)}\n",
    ")\n",
    "plt.title(\"Local Outlier Factor (LOF)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging With One Class SVM:  Hyperparameter Optimization with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_model = BaggingClassifier()\n",
    " \n",
    "param_grid = {\n",
    "    'base_estimator': oneclass_svm,\n",
    "    'n_estimators': list(range(1,8)),\n",
    "    'max_samples':  np.linspace(0.1, 0.5, 5), \n",
    "    'bootstrap': True,\n",
    "    'random_state':42\n",
    "}\n",
    " \n",
    "f1_scorer = make_scorer(f1_score, average='binary')\n",
    "grid_search = GridSearchCV(estimator=bagging_model, param_grid=param_grid, scoring=f1_scorer, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    " \n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation F1 score: \", grid_search.best_score_)\n",
    " \n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_val = best_model.predict(X_val)\n",
    "accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "f1_score_val = f1_score(y_val, y_pred_val, pos_label=1)\n",
    "confusion_matrix_val = confusion_matrix(y_val, y_pred_val, labels=[1,-1])\n",
    "print('accuracy_val: ',accuracy_val)\n",
    "print('f1_score_val: ',f1_score_val)\n",
    " \n",
    " \n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_matrix_val, annot=True, cmap='Blues', fmt='g', xticklabels=[1, -1], yticklabels=[1, -1])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix Validation Set')\n",
    "plt.show()\n",
    " \n",
    " \n",
    "y_pred_test = best_model.predict(X_test)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "f1_score_test = f1_score(y_test, y_pred_test, pos_label=1)\n",
    "confusion_matrix_test = confusion_matrix(y_test, y_pred_test, labels=[1,-1])\n",
    "print('accuracy_test: ',accuracy_test)\n",
    "print('f1_score_test: ',f1_score_test)\n",
    " \n",
    " \n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_matrix_test, annot=True, cmap='Blues', fmt='g', xticklabels=[1, -1], yticklabels=[1, -1])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix Test Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting (AdaBoost) With One Class SVM:  Hyperparameter Optimization with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boosting_model = AdaBoostClassifier()\n",
    " \n",
    "param_grid = {\n",
    "    'base_estimator': oneclass_svm,\n",
    "    'n_estimators': list(range(1,4)),\n",
    "    'learning_rate':  np.linspace(0.1, 1, 5),\n",
    "    'random_state':42\n",
    "}\n",
    " \n",
    "f1_scorer = make_scorer(f1_score, average='binary')\n",
    "grid_search = GridSearchCV(estimator=boosting_model, param_grid=param_grid, scoring=f1_scorer, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    " \n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation F1 score: \", grid_search.best_score_)\n",
    " \n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_val = best_model.predict(X_val)\n",
    "accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "f1_score_val = f1_score(y_val, y_pred_val, pos_label=1)\n",
    "confusion_matrix_val = confusion_matrix(y_val, y_pred_val, labels=[1,-1])\n",
    "print('accuracy_val: ',accuracy_val)\n",
    "print('f1_score_val: ',f1_score_val)\n",
    " \n",
    " \n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_matrix_val, annot=True, cmap='Blues', fmt='g', xticklabels=[1, -1], yticklabels=[1, -1])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix Validation Set')\n",
    "plt.show()\n",
    " \n",
    " \n",
    "y_pred_test = best_model.predict(X_test)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "f1_score_test = f1_score(y_test, y_pred_test, pos_label=1)\n",
    "confusion_matrix_test = confusion_matrix(y_test, y_pred_test, labels=[1,-1])\n",
    "print('accuracy_test: ',accuracy_test)\n",
    "print('f1_score_test: ',f1_score_test)\n",
    " \n",
    " \n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_matrix_test, annot=True, cmap='Blues', fmt='g', xticklabels=[1, -1], yticklabels=[1, -1])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix Test Set')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
